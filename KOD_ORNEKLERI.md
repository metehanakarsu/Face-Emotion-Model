# Kod Ã–rnekleri - Duygu Analizi Projesi

## ğŸ¯ Sunum Raporu Ä°Ã§in Ana Kodlar

### 1. Ana Model SÄ±nÄ±fÄ± - Duygu Analizi

```python
# src/models/emotion_detection.py
import cv2
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array

class EmotionDetector:
    def __init__(self, model_path='data/models/emotion_model.h5'):
        self.emotions = ['KÄ±zgÄ±n', 'Ä°ÄŸrenmiÅŸ', 'KorkmuÅŸ', 'Mutlu', 'ÃœzgÃ¼n', 'ÅaÅŸkÄ±n', 'NÃ¶tr']
        self.model = load_model(model_path)
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )

    def detect_emotion(self, frame):
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = self.face_cascade.detectMultiScale(gray, 1.1, 5)
        
        emotions_detected = []
        for (x, y, w, h) in faces:
            roi = gray[y:y + h, x:x + w]
            roi = cv2.resize(roi, (48, 48))
            roi = roi.astype("float") / 255.0
            roi = img_to_array(roi)
            roi = np.expand_dims(roi, axis=0)
            
            preds = self.model.predict(roi)[0]
            emotion_idx = preds.argmax()
            emotion = self.emotions[emotion_idx]
            emotions_detected.append(emotion)
            
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            cv2.putText(frame, emotion, (x, y - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
        
        return frame, emotions_detected
```

### 2. GUI Ana SÄ±nÄ±fÄ±

```python
# gui_emotion_detection.py
import tkinter as tk
from tkinter import ttk
import cv2
from PIL import Image, ImageTk
import threading

class EmotionGUI:
    def __init__(self, window, window_title):
        self.window = window
        self.window.title(window_title)
        
        # Model yÃ¼kle
        self.model = load_model("data/models/emotion_model.h5")
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
        
        # Video yakalama
        self.cap = None
        self.is_webcam_active = False
        
        # GUI bileÅŸenleri
        self.create_gui()
        
    def create_gui(self):
        # Ana Ã§erÃ§eve
        main_frame = ttk.Frame(self.window)
        main_frame.pack(padx=10, pady=10)
        
        # Video gÃ¶rÃ¼ntÃ¼leme alanÄ±
        self.video_frame = ttk.Frame(main_frame)
        self.video_frame.grid(row=0, column=0, padx=5, pady=5)
        
        self.canvas = tk.Canvas(self.video_frame, width=640, height=480)
        self.canvas.pack()
        
        # Kontrol paneli
        control_frame = ttk.Frame(main_frame)
        control_frame.grid(row=1, column=0, padx=5, pady=5)
        
        self.webcam_btn = ttk.Button(control_frame, text="Webcam BaÅŸlat", 
                                    command=self.toggle_webcam)
        self.webcam_btn.pack(side=tk.LEFT, padx=5)
        
        # Duygu gÃ¶stergeleri
        self.emotion_frame = ttk.Frame(main_frame)
        self.emotion_frame.grid(row=0, column=1, padx=5, pady=5, sticky="n")
        
        self.emotion_bars = {}
        for emotion in ['Kizgin', 'Igrenme', 'Korku', 'Mutlu', 'Uzgun', 'Saskin', 'Notr']:
            frame = ttk.Frame(self.emotion_frame)
            frame.pack(fill=tk.X, padx=5, pady=2)
            
            ttk.Label(frame, text=emotion).pack(side=tk.LEFT)
            progress = ttk.Progressbar(frame, length=100, mode='determinate')
            progress.pack(side=tk.LEFT, padx=5)
            
            self.emotion_bars[emotion] = progress
```

### 3. GerÃ§ek ZamanlÄ± Analiz

```python
# test_model.py
def realtime_emotion_detection():
    # Model yÃ¼kle
    model = load_model("data/models/emotion_model.h5")
    face_cascade = cv2.CascadeClassifier(
        cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
    )
    
    # Webcam baÅŸlat
    cap = cv2.VideoCapture(0)
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
            
        # Gri tonlamaya Ã§evir
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # YÃ¼zleri tespit et
        faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(30, 30))
        
        # Her yÃ¼z iÃ§in iÅŸlem yap
        for (x, y, w, h) in faces:
            roi = gray[y:y + h, x:x + w]
            roi = cv2.resize(roi, (48, 48))
            roi = roi.astype("float") / 255.0
            roi = img_to_array(roi)
            roi = np.expand_dims(roi, axis=0)
            
            # Duygu tahmini
            predictions = model.predict(roi, verbose=0)[0]
            emotion_idx = np.argmax(predictions)
            emotion = EMOTIONS[emotion_idx]
            probability = predictions[emotion_idx]
            
            # SonuÃ§larÄ± Ã§iz
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            cv2.putText(frame, f"{emotion}: {probability:.2f}", 
                       (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        cv2.imshow("Duygu Analizi", frame)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
```

### 4. Toplu Test Ä°ÅŸlemi

```python
# batch_test.py
def batch_test(test_dir, output_dir='sonuclar/batch_test'):
    # Model yÃ¼kle
    model = load_model("data/models/emotion_model.h5")
    
    # GÃ¶rÃ¼ntÃ¼ dosyalarÄ±nÄ± bul
    image_files = []
    for ext in ['*.jpg', '*.jpeg', '*.png']:
        image_files.extend([f for f in os.listdir(test_dir) 
                           if f.lower().endswith(ext[1:])])
    
    results = []
    
    # Her gÃ¶rÃ¼ntÃ¼ iÃ§in tahmin yap
    for img_file in tqdm(image_files):
        img_path = os.path.join(test_dir, img_file)
        
        # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle ve Ã¶n iÅŸle
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (48, 48))
        img = img.astype("float") / 255.0
        img = img_to_array(img)
        img = np.expand_dims(img, axis=0)
        
        # Duygu tahmini
        predictions = model.predict(img, verbose=0)
        emotion_probs = {EMOTIONS[i]: float(prob) for i, prob in enumerate(predictions[0])}
        emotion = max(emotion_probs.items(), key=lambda x: x[1])
        
        # SonuÃ§larÄ± kaydet
        result = {
            'dosya_adi': img_file,
            'tahmin_edilen_duygu': emotion[0],
            'guven_skoru': emotion[1],
            **emotion_probs
        }
        results.append(result)
    
    # SonuÃ§larÄ± DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r ve kaydet
    results_df = pd.DataFrame(results)
    results_df.to_csv(os.path.join(output_dir, 'batch_test_sonuclari.csv'), index=False)
    
    return results_df
```

### 5. Ana Program

```python
# main.py
def main():
    # Kamera baÅŸlat
    cap = cv2.VideoCapture(0)
    
    # DedektÃ¶rleri baÅŸlat
    face_detector = FaceDetector()
    emotion_detector = EmotionDetector()
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
            
        # YÃ¼z tespiti
        frame, faces = face_detector.detect_faces(frame)
        
        # Duygu analizi
        frame, emotions = emotion_detector.detect_emotion(frame)
        
        # Sosyal mesafe kontrolÃ¼
        if len(faces) > 1:
            violations = face_detector.calculate_social_distance(faces)
            for i, j in violations:
                pt1 = (faces[i][0] + faces[i][2]//2, faces[i][1] + faces[i][3]//2)
                pt2 = (faces[j][0] + faces[j][2]//2, faces[j][1] + faces[j][3]//2)
                cv2.line(frame, pt1, pt2, (0, 0, 255), 2)
        
        # Ekranda gÃ¶ster
        cv2.imshow('GerÃ§ek ZamanlÄ± Analiz', frame)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
```

### 6. Veri Ã–n Ä°ÅŸleme

```python
# src/utils/data_preparation.py
def preprocess_image(image_path, target_size=(48, 48)):
    """GÃ¶rÃ¼ntÃ¼yÃ¼ model iÃ§in hazÄ±rlar"""
    # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    
    # Yeniden boyutlandÄ±r
    img = cv2.resize(img, target_size)
    
    # Normalize et
    img = img.astype("float") / 255.0
    
    # BoyutlarÄ± ayarla
    img = img_to_array(img)
    img = np.expand_dims(img, axis=0)
    
    return img

def load_and_preprocess_batch(image_paths, target_size=(48, 48)):
    """Toplu gÃ¶rÃ¼ntÃ¼ yÃ¼kleme ve Ã¶n iÅŸleme"""
    processed_images = []
    
    for path in image_paths:
        try:
            img = preprocess_image(path, target_size)
            processed_images.append(img)
        except Exception as e:
            print(f"Hata ({path}): {str(e)}")
    
    return np.vstack(processed_images)
```

### 7. Ä°statistik Toplama

```python
# test_model.py - EmotionStats sÄ±nÄ±fÄ±
class EmotionStats:
    def __init__(self, window_size=30):
        self.window_size = window_size
        self.emotion_history = deque(maxlen=window_size)
        self.session_stats = {emotion: 0 for emotion in EMOTIONS}
        self.session_start = datetime.now()
        
    def update(self, emotion, probability):
        current_time = datetime.now()
        self.emotion_history.append((emotion, probability))
        self.session_stats[emotion] += 1
        
    def get_current_stats(self):
        if not self.emotion_history:
            return {}
        
        # Son 30 saniyedeki duygu daÄŸÄ±lÄ±mÄ±
        recent_emotions = [e[0] for e in self.emotion_history]
        emotion_counts = {emotion: recent_emotions.count(emotion) 
                         for emotion in EMOTIONS}
        total = len(recent_emotions)
        
        return {
            'son_30_saniye': {
                emotion: count/total for emotion, count in emotion_counts.items()
            },
            'genel_istatistik': {
                emotion: count/sum(self.session_stats.values()) 
                for emotion, count in self.session_stats.items()
            }
        }
```

### 8. Model EÄŸitimi (Jupyter Notebook)

```python
# notebooks/model_development.ipynb
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten

def create_emotion_model():
    """Duygu analizi iÃ§in CNN modeli oluÅŸturur"""
    model = Sequential([
        # Ä°lk konvolÃ¼syon bloÄŸu
        Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),
        MaxPooling2D(2, 2),
        Dropout(0.25),
        
        # Ä°kinci konvolÃ¼syon bloÄŸu
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),
        Dropout(0.25),
        
        # ÃœÃ§Ã¼ncÃ¼ konvolÃ¼syon bloÄŸu
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),
        Dropout(0.25),
        
        # DÃ¼zleÅŸtirme ve tam baÄŸlantÄ±lÄ± katmanlar
        Flatten(),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(7, activation='softmax')  # 7 duygu sÄ±nÄ±fÄ±
    ])
    
    return model

# Model oluÅŸtur ve derle
model = create_emotion_model()
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Model eÄŸitimi
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=50,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(patience=10),
        tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)
    ]
)

# Modeli kaydet
model.save('data/models/emotion_model.h5')
```

### 9. Ana Ã‡alÄ±ÅŸtÄ±rma MenÃ¼sÃ¼

```python
# run_project.py
def main():
    """Ana menÃ¼ ve program seÃ§enekleri"""
    
    def run_gui():
        """GUI versiyonunu Ã§alÄ±ÅŸtÄ±r"""
        try:
            from gui_emotion_detection import EmotionGUI
            root = tk.Tk()
            app = EmotionGUI(root, "Duygu Analizi - GUI")
            root.mainloop()
        except Exception as e:
            messagebox.showerror("Hata", f"GUI baÅŸlatÄ±lamadÄ±: {str(e)}")
    
    def run_realtime():
        """GerÃ§ek zamanlÄ± analizi Ã§alÄ±ÅŸtÄ±r"""
        try:
            from test_model import realtime_emotion_detection
            realtime_emotion_detection()
        except Exception as e:
            print(f"Hata: {str(e)}")
    
    # Ana pencere oluÅŸtur
    root = tk.Tk()
    root.title("Duygu Analizi Projesi - Ana MenÃ¼")
    root.geometry("400x300")
    
    # BaÅŸlÄ±k
    title_label = tk.Label(root, text="Yapay Zeka TabanlÄ±\nDuygu Analizi Projesi", 
                          font=("Arial", 16, "bold"))
    title_label.pack(pady=20)
    
    # Butonlar
    button_frame = tk.Frame(root)
    button_frame.pack(pady=20)
    
    tk.Button(button_frame, text="GUI Versiyonu Ã‡alÄ±ÅŸtÄ±r", 
              command=run_gui, width=25, height=2).pack(pady=5)
    
    tk.Button(button_frame, text="GerÃ§ek ZamanlÄ± Analiz", 
              command=run_realtime, width=25, height=2).pack(pady=5)
    
    root.mainloop()
```

## ğŸ“Š Kod Ä°statistikleri

- **Toplam SatÄ±r**: ~800 satÄ±r
- **Python DosyalarÄ±**: 8 ana dosya
- **SÄ±nÄ±f SayÄ±sÄ±**: 4 ana sÄ±nÄ±f
- **Fonksiyon SayÄ±sÄ±**: 15+ fonksiyon
- **KullanÄ±lan KÃ¼tÃ¼phaneler**: 10+ kÃ¼tÃ¼phane

## ğŸ¯ Sunum Ä°Ã§in Ã–nemli Kod NoktalarÄ±

1. **ModÃ¼ler TasarÄ±m**: Her Ã¶zellik ayrÄ± sÄ±nÄ±flarda
2. **Hata YÃ¶netimi**: Try-catch bloklarÄ± ile gÃ¼venli Ã§alÄ±ÅŸma
3. **Performans Optimizasyonu**: GerÃ§ek zamanlÄ± iÅŸleme
4. **KullanÄ±cÄ± Dostu**: GUI ve komut satÄ±rÄ± seÃ§enekleri
5. **GeniÅŸletilebilir**: Yeni Ã¶zellikler kolayca eklenebilir

---

**Bu kodlar sunum raporuna eklenebilir ve projenin teknik detaylarÄ±nÄ± gÃ¶stermek iÃ§in kullanÄ±labilir.** 